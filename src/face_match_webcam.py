# src/face_match_webcam.py
"""
ì›¹ìº  ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„ ìŠ¤í¬ë¦½íŠ¸
ì›¹ìº ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³  ë“±ë¡ëœ ì¸ë¬¼ì„ ì‹ë³„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì›¹ìº  ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
- ì–¼êµ´ ê°ì§€ ë° ë§¤ì¹­
- ì‹¤ì‹œê°„ í™”ë©´ í‘œì‹œ
- ë§ˆìŠ¤í¬ ê°ì§€ ë° ì ì‘í˜• ì„ê³„ê°’
- í™”ì§ˆ ê¸°ë°˜ ì ì‘í˜• ì„ê³„ê°’
- ì˜¤íƒ ë°©ì§€ (bbox ê¸°ë°˜ ë‹¤ì¤‘ ë§¤ì¹­ í•„í„°ë§, í”„ë ˆì„ ê°„ ì—°ì†ì„± ì²´í¬)
"""

# CUDA ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì • (ê°€ì¥ ë¨¼ì € import)
from utils.device_config import _ensure_cuda_in_path
_ensure_cuda_in_path()

from insightface.app import FaceAnalysis
import cv2
import numpy as np
from pathlib import Path
import csv
import time
from datetime import datetime
from collections import defaultdict
from utils.gallery_loader import load_gallery, match_with_bank_detailed
from utils.device_config import get_device_id, safe_prepare_insightface
from utils.mask_detector import (
    estimate_mask_from_similarity,
    get_adjusted_threshold,
    estimate_face_quality,
)
from utils.face_angle_detector import estimate_face_angle


def l2_normalize(vec: np.ndarray) -> np.ndarray:
    """ë²¡í„°ë¥¼ L2 ì •ê·œí™”"""
    norm = np.linalg.norm(vec)
    if norm == 0:
        return vec
    return vec / norm


def calculate_bbox_iou(bbox1, bbox2):
    """
    ë‘ bbox ê°„ì˜ IoU(Intersection over Union) ê³„ì‚°

    Args:
        bbox1, bbox2: [x1, y1, x2, y2] í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤

    Returns:
        IoU ê°’ (0.0 ~ 1.0)
    """
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2

    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1_inter = max(x1_1, x1_2)
    y1_inter = max(y1_1, y1_2)
    x2_inter = min(x2_1, x2_2)
    y2_inter = min(y2_1, y2_2)

    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return 0.0

    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)

    # ê° bboxì˜ ë©´ì 
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union_area = area1 + area2 - inter_area

    if union_area == 0:
        return 0.0

    return inter_area / union_area


def calculate_bbox_center_distance(bbox1, bbox2):
    """
    ë‘ bboxì˜ ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ ê³„ì‚°

    Args:
        bbox1, bbox2: [x1, y1, x2, y2] í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤

    Returns:
        ì¤‘ì‹¬ì  ê°„ ìœ í´ë¦¬ë“œ ê±°ë¦¬
    """
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2

    center1_x = (x1_1 + x2_1) / 2
    center1_y = (y1_1 + y2_1) / 2
    center2_x = (x1_2 + x2_2) / 2
    center2_y = (y1_2 + y2_2) / 2

    distance = np.sqrt((center1_x - center2_x) ** 2 + (center1_y - center2_y) ** 2)
    return distance


def is_same_face_region(bbox1, bbox2, iou_threshold=0.3, distance_threshold=None):
    """
    ë‘ bboxê°€ ê°™ì€ ì–¼êµ´ ì˜ì—­ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ íŒë‹¨

    Args:
        bbox1, bbox2: [x1, y1, x2, y2] í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤
        iou_threshold: IoU ì„ê³„ê°’ (ê¸°ë³¸ 0.3)
        distance_threshold: ì¤‘ì‹¬ì  ê±°ë¦¬ ì„ê³„ê°’ (Noneì´ë©´ bbox í¬ê¸° ê¸°ë°˜ ìë™ ê³„ì‚°)

    Returns:
        ê°™ì€ ì–¼êµ´ ì˜ì—­ì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    # IoU ê¸°ë°˜ íŒë‹¨
    iou = calculate_bbox_iou(bbox1, bbox2)
    if iou >= iou_threshold:
        return True

    # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒë‹¨ (ë³´ì¡°)
    if distance_threshold is None:
        # bbox í¬ê¸°ì˜ í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì„¤ì •
        w1 = bbox1[2] - bbox1[0]
        h1 = bbox1[3] - bbox1[1]
        w2 = bbox2[2] - bbox2[0]
        h2 = bbox2[3] - bbox2[1]
        avg_size = (w1 + h1 + w2 + h2) / 4
        distance_threshold = avg_size * 0.5  # bbox í¬ê¸°ì˜ 50% ì´ë‚´ë©´ ê°™ì€ ì–¼êµ´ë¡œ ê°„ì£¼

    distance = calculate_bbox_center_distance(bbox1, bbox2)
    if distance <= distance_threshold:
        return True

    return False


def process_frame(img, app, gallery, BASE_THRESH, frame_idx=None):
    """
    ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ - ëª¨ë“  ì–¼êµ´ ê°ì§€ ë° ë§¤ì¹­

    Args:
        img: BGR ì´ë¯¸ì§€ (numpy array)
        app: FaceAnalysis ê°ì²´
        gallery: ê°¤ëŸ¬ë¦¬ ë”•ì…”ë„ˆë¦¬
        BASE_THRESH: ê¸°ë³¸ ì„ê³„ê°’
        frame_idx: í”„ë ˆì„ ì¸ë±ìŠ¤ (Noneì´ë©´ ì´ë¯¸ì§€)

    Returns:
        results: ì–¼êµ´ë³„ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # ì–¼êµ´ ê²€ì¶œ
    faces = app.get(img)

    if len(faces) == 0:
        return []

    results = []

    for i, face in enumerate(faces):
        face_emb = face.embedding.astype("float32")
        face_emb_normalized = l2_normalize(face_emb)

        # ì–¼êµ´ ê°ë„ ì¶”ì •
        angle_type, yaw_angle = estimate_face_angle(face)

        # Bank ê¸°ë°˜ ë§¤ì¹­ (ìƒì„¸ ì •ë³´ í¬í•¨)
        best_id, best_sim, second_sim = match_with_bank_detailed(face_emb, gallery)

        # 2ì°¨ í™•ì¸: ìµœê³  ìœ ì‚¬ë„ì™€ ë‘ ë²ˆì§¸ ìœ ì‚¬ë„ì˜ ì°¨ì´ í™•ì¸ (ì˜¤íƒ ë°©ì§€)
        sim_gap = best_sim - second_sim if second_sim > -1 else best_sim
        min_gap = 0.05  # ìµœì†Œ ì°¨ì´ (5% ì´ìƒ ì°¨ì´ í•„ìš”)

        # í™”ì§ˆ ì¶”ì • (ì–¼êµ´ í¬ê¸° ê¸°ë°˜)
        img_height, img_width = img.shape[:2]
        face_quality = estimate_face_quality(face.bbox, (img_height, img_width))

        # ë§ˆìŠ¤í¬ ê°€ëŠ¥ì„± ì¶”ì • ë° ì ì‘í˜• ì„ê³„ê°’ (í™”ì§ˆ ê³ ë ¤)
        mask_prob = estimate_mask_from_similarity(best_sim)
        use_thresh = get_adjusted_threshold(
            BASE_THRESH, mask_prob, best_sim, face_quality
        )

        # ë§¤ì¹­ ì—¬ë¶€: ì„ê³„ê°’ í†µê³¼ + ìœ ì‚¬ë„ ì°¨ì´ê°€ ì¶©ë¶„í•´ì•¼ í•¨
        is_match = (best_sim >= use_thresh) and (sim_gap >= min_gap)

        # ê²°ê³¼ ì €ì¥
        results.append(
            {
                "face_idx": i,
                "frame_idx": frame_idx,
                "angle_type": angle_type,
                "yaw_angle": yaw_angle,
                "best_id": best_id,
                "similarity": best_sim,
                "second_similarity": second_sim,
                "sim_gap": sim_gap,
                "threshold": use_thresh,
                "is_match": is_match,
                "bbox": face.bbox,
                "mask_prob": mask_prob,
                "face_quality": face_quality,
                "embedding": face_emb_normalized,
            }
        )

    # ê°™ì€ í”„ë ˆì„ ë‚´ì—ì„œ ë§¤ì¹­ í•„í„°ë§ (bbox ê¸°ë°˜ ë‹¤ì¤‘ ë§¤ì¹­ ì²˜ë¦¬)
    if len(results) > 1:
        matched_results = []
        unmatched_results = []

        for r in results:
            if r["is_match"]:
                matched_results.append(r)
            else:
                unmatched_results.append(r)

        if len(matched_results) > 1:
            # bbox ê¸°ë°˜ìœ¼ë¡œ ê°™ì€ ì–¼êµ´ ì˜ì—­ ê·¸ë£¹í™”
            face_groups = []
            used_indices = set()

            for i, r1 in enumerate(matched_results):
                if i in used_indices:
                    continue

                # ìƒˆë¡œìš´ ê·¸ë£¹ ì‹œì‘
                group = [r1]
                used_indices.add(i)

                # ê°™ì€ ì–¼êµ´ ì˜ì—­ì¸ ë‹¤ë¥¸ ë§¤ì¹­ ì°¾ê¸°
                for j, r2 in enumerate(matched_results):
                    if j <= i or j in used_indices:
                        continue

                    if is_same_face_region(r1["bbox"], r2["bbox"]):
                        group.append(r2)
                        used_indices.add(j)

                face_groups.append(group)

            # ê° ê·¸ë£¹ ì²˜ë¦¬
            filtered_matched = []

            for group in face_groups:
                if len(group) == 1:
                    # ë‹¨ì¼ ë§¤ì¹­: ê·¸ëŒ€ë¡œ ìœ ì§€
                    filtered_matched.append(group[0])
                else:
                    # ê°™ì€ ì–¼êµ´ ì˜ì—­ì—ì„œ ì—¬ëŸ¬ ì¸ë¬¼ë¡œ ë§¤ì¹­ë¨ â†’ ì˜¤íƒ ê°€ëŠ¥ì„±
                    group.sort(key=lambda x: x["similarity"], reverse=True)

                    best_match = group[0]
                    second_match = group[1] if len(group) > 1 else None

                    # sim_gapì´ ì¶©ë¶„íˆ í¬ë©´ ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë§Œ ì¸ì •
                    min_gap_for_confidence = 0.10
                    if second_match and (best_match["sim_gap"] >= min_gap_for_confidence):
                        filtered_matched.append(best_match)
                        # ë‚˜ë¨¸ì§€ëŠ” ë§¤ì¹­ í•´ì œ
                        for other in group[1:]:
                            other["is_match"] = False
                            unmatched_results.append(other)
                    else:
                        # ì• ë§¤í•œ ê²½ìš° ëª¨ë‘ ë§¤ì¹­ í•´ì œ
                        for match in group:
                            match["is_match"] = False
                            unmatched_results.append(match)

            # ë‚®ì€ ì‹ ë¢°ë„ ì²´í¬
            final_filtered = []
            for match in filtered_matched:
                quality = match.get("face_quality", "medium")
                sim_threshold = (
                    0.38 if quality == "high" else (0.35 if quality == "medium" else 0.32)
                )
                gap_threshold = (
                    0.10 if quality == "high" else (0.08 if quality == "medium" else 0.06)
                )

                if match["similarity"] >= sim_threshold and match["sim_gap"] >= gap_threshold:
                    final_filtered.append(match)
                else:
                    match["is_match"] = False
                    unmatched_results.append(match)

            results = final_filtered + unmatched_results

        elif len(matched_results) == 1:
            # ë‹¨ì¼ ë§¤ì¹­ë„ ë‚®ì€ ì‹ ë¢°ë„ë©´ ë§¤ì¹­ í•´ì œ
            match = matched_results[0]
            quality = match.get("face_quality", "medium")
            sim_threshold = (
                0.38 if quality == "high" else (0.35 if quality == "medium" else 0.32)
            )
            gap_threshold = (
                0.10 if quality == "high" else (0.08 if quality == "medium" else 0.06)
            )

            if match["similarity"] < sim_threshold or match["sim_gap"] < gap_threshold:
                match["is_match"] = False
                unmatched_results.append(match)
                results = unmatched_results
            else:
                results = matched_results + unmatched_results
        else:
            results = unmatched_results

    return results


def main():
    # ===== ì„¤ì • =====
    emb_dir = Path("outputs") / "embeddings"  # ë“±ë¡ ì„ë² ë”© í´ë”
    BASE_THRESH = 0.32  # ê¸°ë³¸ ì„ê³„ê°’ (í™”ì§ˆ ê¸°ë°˜ ì¡°ì • ì „)

    # ì¶œë ¥ í´ë” êµ¬ì¡° (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_base_dir = Path("outputs") / "results" / f"webcam_{timestamp}"

    matches_dir = output_base_dir / "matches"
    logs_dir = output_base_dir / "logs"

    # í´ë” ìƒì„±
    matches_dir.mkdir(parents=True, exist_ok=True)
    logs_dir.mkdir(parents=True, exist_ok=True)

    log_path = logs_dir / "detection_log.csv"

    print("=" * 70)
    print("ğŸ“¹ ì›¹ìº  ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„ ì‹œìŠ¤í…œ")
    print("=" * 70)
    print(f"   ì„ë² ë”© í´ë”: {emb_dir}")
    print(f"   ê¸°ë³¸ ì„ê³„ê°’: {BASE_THRESH}")
    print(f"   ì¶œë ¥ í´ë”: {output_base_dir}")
    print(f"     - ë§¤ì¹­ ìŠ¤ëƒ…ìƒ·: {matches_dir}")
    print(f"     - ë¡œê·¸ íŒŒì¼: {logs_dir}")
    print()

    # 1. ê°¤ëŸ¬ë¦¬ ë¡œë“œ
    gallery = load_gallery(emb_dir, use_bank=True)
    if not gallery:
        raise RuntimeError(f"ê°¤ëŸ¬ë¦¬ ë¹„ì–´ ìˆìŒ: {emb_dir}")

    print("ğŸ‘¥ ê°¤ëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ:", list(gallery.keys()))
    for pid, data in gallery.items():
        if data.ndim == 2:
            print(f"  - {pid}: bank ({data.shape[0]}ê°œ ì„ë² ë”©)")
        else:
            print(f"  - {pid}: centroid")
    print()

    # 2. InsightFace ì¤€ë¹„
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")

    app = FaceAnalysis(name="buffalo_l")
    actual_device_id = safe_prepare_insightface(app, device_id, det_size=(640, 640))
    if actual_device_id != device_id:
        print(f"   (ì‹¤ì œ ì‚¬ìš©: {'GPU' if actual_device_id >= 0 else 'CPU'})")
    print("   Detection size: (640, 640)")
    print()

    # 3. CSV ë¡œê·¸ íŒŒì¼ ì—´ê¸°
    log_f = open(log_path, "w", newline="", encoding="utf-8")
    log_writer = csv.writer(log_f)
    log_writer.writerow(
        [
            "frame",
            "person_id",
            "similarity",
            "threshold",
            "is_match",
            "angle_type",
            "yaw_angle",
            "mask_prob",
            "sim_gap",
            "face_quality",
            "x1",
            "y1",
            "x2",
            "y2",
        ]
    )

    # 4. í†µê³„ ë³€ìˆ˜ ì´ˆê¸°í™”
    frame_idx = 0
    hit_count = 0
    total_faces_detected = 0
    max_sim_ever = -1.0
    person_stats = defaultdict(lambda: {"count": 0, "max_sim": 0.0})
    frame_history = defaultdict(list)  # í”„ë ˆì„ ê°„ ì—°ì†ì„± ì²´í¬ìš©
    continuity_window = 5

    start_time = time.time()

    # 5. ì›¹ìº  ì´ˆê¸°í™”
    print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
    print()

    # ğŸ‘‰ cam_test.py ìŠ¤íƒ€ì¼: Windowsì—ì„œ DirectShow ë°±ì—”ë“œ ì‚¬ìš©
    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

    if not cap.isOpened():
        raise RuntimeError(
            "ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            "ê°€ëŠ¥í•œ ì›ì¸:\n"
            "  1. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŒ\n"
            "  2. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì›¹ìº ì„ ì‚¬ìš© ì¤‘\n"
            "  3. ì›¹ìº  ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ\n"
            "  4. ê¶Œí•œ ë¬¸ì œ (Windows: ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸)"
        )

    # í•´ìƒë„ëŠ” ìš°ì„  ê¸°ë³¸ê°’ ì‚¬ìš© (ë¬¸ì œ ì—†ìœ¼ë©´ ì´í›„ì— ì¡°ì • ê°€ëŠ¥)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    print(f"   í•´ìƒë„: {width}x{height}")
    print(f"   FPS: {fps:.2f}")
    print("   ì‹¤ì‹œê°„ ì‹ë³„ ì‹œì‘... (ì¢…ë£Œ: 'q' í‚¤ ëˆ„ë¥´ê¸°)")
    print()

    # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •
    PROCESS_EVERY_N_FRAMES = 2  # 2í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ì„±ëŠ¥ ê³ ë ¤)

    # 6. ì‹¤ì‹œê°„ í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„
    print("ğŸ’¡ ì‹¤ì‹œê°„ í™”ë©´ì´ í‘œì‹œë©ë‹ˆë‹¤. 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    print()

    # ì´ì „ í”„ë ˆì„ì˜ ê²°ê³¼ë¥¼ ì €ì¥ (ìŠ¤í‚µëœ í”„ë ˆì„ì—ë„ í‘œì‹œí•˜ê¸° ìœ„í•´)
    last_frame_with_boxes = None

    while True:
        ret, frame = cap.read()
        if not ret or frame is None or frame.size == 0:
            print("âš  ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # í”„ë ˆì„ ìŠ¤í‚µìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
        if frame_idx % PROCESS_EVERY_N_FRAMES != 0:
            frame_idx += 1
            # ìŠ¤í‚µëœ í”„ë ˆì„ì—ëŠ” ì´ì „ ê²°ê³¼ í‘œì‹œ
            if last_frame_with_boxes is not None:
                cv2.imshow("FaceWatch - ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„", last_frame_with_boxes)
            else:
                cv2.imshow("FaceWatch - ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„", frame)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                print("\nâš  ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
                break
            continue

        # í”„ë ˆì„ ì²˜ë¦¬
        frame_results = process_frame(frame, app, gallery, BASE_THRESH, frame_idx)
        
        # ê²°ê³¼ë¥¼ í‘œì‹œí•  í”„ë ˆì„ ë³µì‚¬
        display_frame = frame.copy()

        if frame_results:
            total_faces_detected += len(frame_results)

            # í”„ë ˆì„ ê°„ ì—°ì†ì„± ì²´í¬ (ë§¤ì¹­ëœ ê²°ê³¼ì— ëŒ€í•´)
            # ì›¹ìº ì€ ì‹¤ì‹œê°„ì´ë¯€ë¡œ ì—°ì†ì„± ì²´í¬ë¥¼ ì™„í™”
            matched_in_frame = [r for r in frame_results if r["is_match"]]

            for r in matched_in_frame:
                person_id = r["best_id"]
                recent_frames = frame_history[person_id]

                # ì—°ì†ì„± ì²´í¬ (ì›¹ìº ì€ ì‹¤ì‹œê°„ì´ë¯€ë¡œ ì™„í™”ëœ ê¸°ì¤€ ì‚¬ìš©)
                has_continuity = False
                if recent_frames:
                    last_frame = recent_frames[-1]
                    frame_gap = frame_idx - last_frame
                    # ì›¹ìº ì€ ì—°ì†ì„± ìœˆë„ìš°ë¥¼ ë” í¬ê²Œ ì„¤ì • (10í”„ë ˆì„)
                    if frame_gap <= continuity_window * 2:
                        has_continuity = True

                # ì—°ì†ì„±ì´ ì—†ê³  ìœ ì‚¬ë„ê°€ ë§¤ìš° ë‚®ì€ ê²½ìš°ë§Œ ë§¤ì¹­ í•´ì œ (ì›¹ìº ì€ ë” ê´€ëŒ€í•˜ê²Œ)
                quality = r.get("face_quality", "medium")
                continuity_threshold = (
                    0.35 if quality == "high" else (0.33 if quality == "medium" else 0.30)
                )
                if not has_continuity and r["similarity"] < continuity_threshold:
                    r["is_match"] = False

            for r in frame_results:
                x1, y1, x2, y2 = map(int, r["bbox"])

                # CSV ë¡œê·¸ ê¸°ë¡
                face_quality = r.get("face_quality", "unknown")
                log_writer.writerow(
                    [
                        frame_idx,
                        r["best_id"],
                        r["similarity"],
                        r["threshold"],
                        int(r["is_match"]),
                        r["angle_type"],
                        r["yaw_angle"],
                        r["mask_prob"],
                        r["sim_gap"],
                        face_quality,
                        x1,
                        y1,
                        x2,
                        y2,
                    ]
                )

                # í†µê³„ ì—…ë°ì´íŠ¸
                if r["similarity"] > max_sim_ever:
                    max_sim_ever = r["similarity"]

                if r["is_match"]:
                    hit_count += 1
                    person_stats[r["best_id"]]["count"] += 1
                    if r["similarity"] > person_stats[r["best_id"]]["max_sim"]:
                        person_stats[r["best_id"]]["max_sim"] = r["similarity"]

                    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                    frame_history[r["best_id"]].append(frame_idx)
                    if len(frame_history[r["best_id"]]) > continuity_window * 2:
                        frame_history[r["best_id"]] = frame_history[r["best_id"]][
                            -continuity_window:
                        ]

                    # ìŠ¤ëƒ…ìƒ· ì €ì¥ (30í”„ë ˆì„ë§ˆë‹¤, ë§¤ì¹­ëœ ê²½ìš°ë§Œ)
                    if frame_idx % 30 == 0:
                        out_name = (
                            f"match_f{frame_idx:06d}_{r['best_id']}_{r['similarity']:.2f}.jpg"
                        )
                        cv2.imwrite(str(matches_dir / out_name), display_frame)

                # í™”ë©´ì— í‘œì‹œ
                label = f"{r['best_id']} {r['similarity']:.2f}"
                if r.get("face_quality"):
                    quality_emoji = {
                        "high": "ğŸ”",
                        "medium": "ğŸ“·",
                        "low": "ğŸ“±",
                    }.get(r["face_quality"], "")
                    label += f" [{r['face_quality']}{quality_emoji}]"
                if r["mask_prob"] > 0.3:
                    label += f" [M:{r['mask_prob']:.1f}]"
                if r["angle_type"] != "front":
                    label += f" [{r['angle_type']}]"

                color = (0, 255, 0) if r["is_match"] else (0, 0, 255)

                # ë°•ìŠ¤ì™€ í…ìŠ¤íŠ¸ë¥¼ display_frameì— ê·¸ë¦¬ê¸°
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(
                    display_frame,
                    label,
                    (x1, max(0, y1 - 10)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    color,
                    2,
                )

        # í™”ë©´ ìƒë‹¨ì— ì •ë³´ í‘œì‹œ
        info_text = f"Frame: {frame_idx} | Matches: {hit_count} | Faces: {total_faces_detected}"
        cv2.putText(
            display_frame,
            info_text,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )
        cv2.putText(
            display_frame,
            "Press 'q' to quit",
            (10, display_frame.shape[0] - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )

        # ì´ì „ í”„ë ˆì„ ê²°ê³¼ ì €ì¥ (ìŠ¤í‚µëœ í”„ë ˆì„ì— í‘œì‹œí•˜ê¸° ìœ„í•´)
        last_frame_with_boxes = display_frame.copy()

        # GUI í‘œì‹œ
        cv2.imshow("FaceWatch - ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„", display_frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            print("\nâš  ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
            break

        frame_idx += 1

    cap.release()
    cv2.destroyAllWindows()
    log_f.close()

    elapsed = time.time() - start_time

    # 7. ìµœì¢… í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print("=" * 70)
    print(f"   ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"   ì´ í”„ë ˆì„ ìˆ˜: {frame_idx}")
    print(f"   ì²˜ë¦¬ ì†ë„: {frame_idx / elapsed:.2f} FPS")
    print(f"   ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {total_faces_detected}ê°œ")
    print(f"   ë§¤ì¹­ëœ ì–¼êµ´ ìˆ˜: {hit_count}ê°œ")
    print(f"   ê´€ì¸¡ëœ ìµœëŒ€ ìœ ì‚¬ë„: {max_sim_ever:.3f}")
    print()

    # ì¸ë¬¼ë³„ í†µê³„
    if person_stats:
        print("ğŸ“Š ì¸ë¬¼ë³„ ë§¤ì¹­ í†µê³„:")
        for person_id, stats in sorted(
            person_stats.items(), key=lambda x: x[1]["count"], reverse=True
        ):
            print(
                f"   {person_id:10s}: {stats['count']:4d}íšŒ ë§¤ì¹­, "
                f"ìµœê³  ìœ ì‚¬ë„: {stats['max_sim']:.3f}"
            )
        print()

    # ì¶œë ¥ íŒŒì¼ ì •ë³´
    print("ğŸ“ ì¶œë ¥ íŒŒì¼:")
    print(f"   ì¶œë ¥ í´ë”: {output_base_dir}")
    print(f"   CSV ë¡œê·¸: {log_path}")
    print(f"   ë§¤ì¹­ ìŠ¤ëƒ…ìƒ·: {matches_dir} ({hit_count}ì¥)")
    print()


if __name__ == "__main__":
    main()
