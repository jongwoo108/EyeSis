"""
ê°ë„ë³„ ì„ë² ë”© ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
ìˆ˜ë™ ì´¬ì˜í•œ left, right, top ì‚¬ì§„ì—ì„œ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì €ì¥
"""
import sys
import json
from pathlib import Path
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CUDA ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì •
from src.utils.device_config import _ensure_cuda_in_path
_ensure_cuda_in_path()

from insightface.app import FaceAnalysis
from src.utils.device_config import get_device_id, safe_prepare_insightface
from src.face_enroll import get_main_face_embedding, l2_normalize
from src.utils.face_angle_detector import estimate_face_angle
import cv2

# ì„¤ì •
ENROLL_DIR = PROJECT_ROOT / "images" / "enroll"
OUTPUT_DIR = PROJECT_ROOT / "outputs" / "embeddings_manual"  # ë¹„êµ í…ŒìŠ¤íŠ¸ìš© ë³„ë„ í´ë”

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".JPG", ".JPEG", ".PNG", ".BMP"}

# ê°ë„ë³„ íŒŒì¼ëª… íŒ¨í„´
ANGLE_PATTERNS = {
    "left": ["left", "_l", "_L", "fleft"],  # fleft = front-left (ì •ë©´ì´ë©´ì„œ ì™¼ìª½)
    "right": ["right", "_r", "_R", "fright"],  # fright = front-right (ì •ë©´ì´ë©´ì„œ ì˜¤ë¥¸ìª½)
    "top": ["top", "_t", "_T", "up", "_u", "_U"]
}


def detect_angle_from_filename(filename: str) -> str:
    """
    íŒŒì¼ëª…ì—ì„œ ê°ë„ ì¶”ì •
    
    Args:
        filename: ì´ë¯¸ì§€ íŒŒì¼ëª…
    
    Returns:
        ê°ë„ íƒ€ì…: "left", "right", "top", ë˜ëŠ” "front" (ê¸°ë³¸ê°’)
    """
    filename_lower = filename.lower()
    
    # fleft, frightëŠ” ìš°ì„ ì ìœ¼ë¡œ ì²˜ë¦¬ (front-left, front-right)
    # frigntëŠ” frightì˜ ì˜¤íƒ€ë¡œ ë³´ì´ì§€ë§Œ ì¸ì‹í•˜ë„ë¡ ì²˜ë¦¬
    if "fleft" in filename_lower:
        return "left"  # front-leftëŠ” left ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
    if "fright" in filename_lower or "frignt" in filename_lower:
        return "right"  # front-rightëŠ” right ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
    
    for angle, patterns in ANGLE_PATTERNS.items():
        for pattern in patterns:
            if pattern in filename_lower:
                return angle
    
    return "front"  # ê¸°ë³¸ê°’


def extract_angle_embeddings():
    """ê°ë„ë³„ ì„ë² ë”© ì¶”ì¶œ"""
    print("=" * 70)
    print("ğŸ“¸ ê°ë„ë³„ ì„ë² ë”© ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 70)
    print(f"ì…ë ¥ í´ë”: {ENROLL_DIR}")
    print(f"ì¶œë ¥ í´ë”: {OUTPUT_DIR}")
    print()
    
    # ì¶œë ¥ í´ë” ìƒì„±
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # InsightFace ì´ˆê¸°í™”
    print("ğŸ”§ InsightFace ì´ˆê¸°í™” ì¤‘...")
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"   ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")
    
    app = FaceAnalysis(name="buffalo_l")
    # ì¸¡ë©´ ì–¼êµ´ ê°ì§€ë¥¼ ìœ„í•´ detection sizeë¥¼ ë” í¬ê²Œ ì„¤ì •
    actual_device_id = safe_prepare_insightface(app, device_id, det_size=(1280, 1280))
    if actual_device_id != device_id:
        print(f"   (ì‹¤ì œ ì‚¬ìš©: {'GPU' if actual_device_id >= 0 else 'CPU'})")
    print()
    
    # ê° ì¸ë¬¼ë³„ í´ë” í™•ì¸
    if not ENROLL_DIR.exists():
        print(f"âŒ enroll í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ENROLL_DIR}")
        return
    
    person_dirs = [d for d in ENROLL_DIR.iterdir() if d.is_dir()]
    
    if not person_dirs:
        print(f"âš ï¸ {ENROLL_DIR} ì•ˆì— ì¸ë¬¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ‘¥ ì²˜ë¦¬ ëŒ€ìƒ ì¸ë¬¼: {len(person_dirs)}ëª…")
    for d in person_dirs:
        print(f"   - {d.name}")
    print()
    
    # ê° ì¸ë¬¼ë³„ ì²˜ë¦¬
    all_results = {}
    
    for person_dir in person_dirs:
        person_id = person_dir.name
        print(f"\n{'='*70}")
        print(f"ğŸ‘¤ {person_id} ì²˜ë¦¬ ì¤‘...")
        print(f"{'='*70}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_files = [
            f for f in sorted(person_dir.iterdir())
            if f.is_file() and f.suffix.lower() in IMG_EXTS
        ]
        
        if not image_files:
            print(f"  âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ê°ë„ë³„ë¡œ ê·¸ë£¹í™”
        angle_groups = {
            "left": [],
            "right": [],
            "top": [],
            "front": []
        }
        
        for img_file in image_files:
            angle = detect_angle_from_filename(img_file.name)
            angle_groups[angle].append(img_file)
        
        # ê° ê°ë„ë³„ ì„ë² ë”© ì¶”ì¶œ
        person_results = {
            "person_id": person_id,
            "embeddings": {}
        }
        
        # ê°ë„ ì •ë³´ ì €ì¥ìš© (í‰ê°€ ì‹œ ì‚¬ìš©)
        angles_info = {
            "angle_types": [],
            "yaw_angles": [],
            "pitch_angles": [],
            "file_mapping": []  # ê° ì„ë² ë”©ì´ ì–´ë–¤ íŒŒì¼ì—ì„œ ì™”ëŠ”ì§€
        }
        
        for angle_type, img_files in angle_groups.items():
            if not img_files:
                continue
            
            print(f"\n  ğŸ“ {angle_type.upper()} ê°ë„ ({len(img_files)}ê°œ íŒŒì¼):")
            
            embeddings_list = []
            angle_data_list = []  # ê° ì´ë¯¸ì§€ì˜ ê°ë„ ì •ë³´
            
            for img_file in img_files:
                print(f"    â–¶ {img_file.name}")
                
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì–¼êµ´ ê°ì§€
                img = cv2.imread(str(img_file))
                if img is None:
                    print(f"      âŒ ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨")
                    continue
                
                faces = app.get(img)
                if len(faces) == 0:
                    # ì „ì²˜ë¦¬ í›„ ì¬ì‹œë„
                    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
                    l, a, b = cv2.split(lab)
                    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                    l = clahe.apply(l)
                    enhanced = cv2.merge([l, a, b])
                    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
                    faces = app.get(enhanced)
                    
                    if len(faces) == 0:
                        h, w = img.shape[:2]
                        if h < 1280 or w < 1280:
                            scale = max(1280 / h, 1280 / w)
                            new_h, new_w = int(h * scale), int(w * scale)
                            upscaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                            faces = app.get(upscaled)
                            
                            # ì—…ìŠ¤ì¼€ì¼ë§ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ì „ì²˜ë¦¬ + ì—…ìŠ¤ì¼€ì¼ë§ ì¡°í•© ì‹œë„
                            if len(faces) == 0:
                                upscaled_enhanced = cv2.resize(enhanced, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                                faces = app.get(upscaled_enhanced)
                
                if len(faces) == 0:
                    print(f"      âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨")
                    continue
                
                # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                faces_sorted = sorted(
                    faces,
                    key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]),
                    reverse=True
                )
                main_face = faces_sorted[0]
                
                # ì„ë² ë”© ì¶”ì¶œ
                emb = main_face.embedding.astype("float32")
                emb = l2_normalize(emb)
                embeddings_list.append(emb)
                
                # ê°ë„ ì¸¡ì •
                detected_angle_type, yaw_angle = estimate_face_angle(main_face)
                
                # Pitch ê°ë„ë„ ê³„ì‚° (estimate_face_angle ë‚´ë¶€ ë¡œì§ ì‚¬ìš©)
                kps = main_face.kps
                left_eye = kps[0]
                right_eye = kps[1]
                nose = kps[2]
                left_mouth = kps[3]
                right_mouth = kps[4]
                
                eye_center_y = (left_eye[1] + right_eye[1]) / 2
                mouth_center_y = (left_mouth[1] + right_mouth[1]) / 2
                eye_to_mouth_distance = abs(mouth_center_y - eye_center_y)
                eye_to_nose_distance = abs(nose[1] - eye_center_y)
                
                if eye_to_mouth_distance > 1e-6:
                    nose_ratio = eye_to_nose_distance / eye_to_mouth_distance
                    pitch_angle = (0.5 - nose_ratio) * 90.0
                else:
                    pitch_angle = 0.0
                
                angle_data_list.append({
                    "file": img_file.name,
                    "detected_angle_type": detected_angle_type,
                    "yaw_angle": float(yaw_angle),
                    "pitch_angle": float(pitch_angle),
                    "file_angle_type": angle_type  # íŒŒì¼ëª… ê¸°ë°˜ ê°ë„
                })
                
                angles_info["angle_types"].append(angle_type)
                angles_info["yaw_angles"].append(float(yaw_angle))
                angles_info["pitch_angles"].append(float(pitch_angle))
                angles_info["file_mapping"].append({
                    "file": img_file.name,
                    "angle_type": angle_type,
                    "detected_angle_type": detected_angle_type,
                    "yaw": float(yaw_angle),
                    "pitch": float(pitch_angle)
                })
                
                print(f"      âœ… ì„ë² ë”© ì¶”ì¶œ ì™„ë£Œ (ê°ë„: {detected_angle_type}, yaw: {yaw_angle:.1f}Â°, pitch: {pitch_angle:.1f}Â°)")
            
            if embeddings_list:
                # ì—¬ëŸ¬ ì„ë² ë”©ì˜ í‰ê·  (centroid)
                embeddings_array = np.stack(embeddings_list, axis=0)
                centroid = embeddings_array.mean(axis=0)
                centroid = l2_normalize(centroid)
                
                # ì €ì¥
                person_output_dir = OUTPUT_DIR / person_id
                person_output_dir.mkdir(parents=True, exist_ok=True)
                
                # ê°ë„ë³„ ì„ë² ë”© ì €ì¥
                embedding_file = person_output_dir / f"embedding_{angle_type}.npy"
                np.save(embedding_file, centroid)
                
                # ëª¨ë“  ì„ë² ë”©ë„ ì €ì¥ (ì„ íƒì )
                bank_file = person_output_dir / f"bank_{angle_type}.npy"
                np.save(bank_file, embeddings_array)
                
                # ê°ë„ ì •ë³´ ì €ì¥ (í‰ê°€ ì‹œ ì‚¬ìš©)
                angles_file = person_output_dir / "angles_manual.json"
                with open(angles_file, 'w', encoding='utf-8') as f:
                    json.dump(angles_info, f, indent=2, ensure_ascii=False)
                
                person_results["embeddings"][angle_type] = {
                    "file": str(embedding_file.relative_to(PROJECT_ROOT)),
                    "count": len(embeddings_list),
                    "centroid_norm": float(np.linalg.norm(centroid)),
                    "angles": angle_data_list
                }
                
                print(f"    ğŸ’¾ ì €ì¥ ì™„ë£Œ: {embedding_file.name} ({len(embeddings_list)}ê°œ ì„ë² ë”©)")
                print(f"    ğŸ’¾ ê°ë„ ì •ë³´ ì €ì¥: {angles_file.name}")
        
        all_results[person_id] = person_results
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½ ì €ì¥
    summary_file = OUTPUT_DIR / "extraction_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    print("âœ… ì¶”ì¶œ ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
    
    for person_id, result in all_results.items():
        print(f"\n  ğŸ‘¤ {person_id}:")
        for angle_type, info in result["embeddings"].items():
            print(f"    - {angle_type}: {info['count']}ê°œ ì„ë² ë”©")
    
    print(f"\nğŸ“ ì €ì¥ ìœ„ì¹˜:")
    print(f"   {OUTPUT_DIR.relative_to(PROJECT_ROOT)}")
    print(f"\nğŸ“„ ìš”ì•½ íŒŒì¼:")
    print(f"   {summary_file.relative_to(PROJECT_ROOT)}")
    print("=" * 70)


if __name__ == "__main__":
    extract_angle_embeddings()


