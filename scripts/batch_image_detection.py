"""
ì´ë¯¸ì§€ ë°°ì¹˜ ì¸ì‹ ìŠ¤í¬ë¦½íŠ¸
images/test/ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥
"""
import sys
import json
from pathlib import Path
import cv2
import numpy as np
from typing import List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CUDA ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì •
from src.utils.device_config import _ensure_cuda_in_path
_ensure_cuda_in_path()

from insightface.app import FaceAnalysis
from src.utils.device_config import get_device_id, safe_prepare_insightface
from backend.database import SessionLocal, get_db
from backend.main import process_detection, load_persons_from_db

# ì„¤ì •
TEST_IMAGE_DIR = PROJECT_ROOT / "images" / "test_easy"
OUTPUT_DIR = PROJECT_ROOT / "outputs" / "test_results_base_only_easy"  # Base Bankë§Œ ì‚¬ìš© ëª¨ë“œ
OUTPUT_IMAGES_DIR = OUTPUT_DIR / "images"
OUTPUT_JSON_DIR = OUTPUT_DIR / "annotations"

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".JPG", ".JPEG", ".PNG", ".BMP"}


def process_single_image(image_path: Path, db) -> Dict:
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
    
    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\nğŸ“· ì²˜ë¦¬ ì¤‘: {image_path.name}")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"  âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
        return None
    
    # BGR to RGB ë³€í™˜ (process_detectionì€ RGBë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŒ)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰ (ì „ì²´ DB ê²€ìƒ‰)
    tracking_state = {"tracks": {}}
    detection_result = process_detection(
        frame=img_rgb,
        suspect_ids=None,  # ì „ì²´ ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰
        db=db,
        tracking_state=tracking_state
    )
    
    # ê²°ê³¼ ì¶”ì¶œ
    detections = detection_result.get("detections", [])
    
    # ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ìƒì„±
    img_with_boxes = img.copy()
    
    # ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°
    annotation = {
        "image_path": str(image_path.relative_to(PROJECT_ROOT)),
        "image_name": image_path.name,
        "faces": []
    }
    
    # ê° ê°ì§€ ê²°ê³¼ì— ëŒ€í•´ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ë° ì–´ë…¸í…Œì´ì…˜ ìˆ˜ì§‘
    for detection in detections:
        bbox = detection["bbox"]
        x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])
        
        # ìƒ‰ìƒ ê²°ì •
        status = detection.get("status", "unknown")
        if status == "criminal":
            color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
        elif status == "normal":
            color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
        else:  # unknown
            color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (BGR)
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3)
        cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 3)
        
        # ë ˆì´ë¸” ìƒì„±
        name = detection.get("name", "Unknown")
        confidence = detection.get("confidence", 0)
        label = f"{name} ({confidence}%)"
        
        # ë ˆì´ë¸” ë°°ê²½ (ê°€ë…ì„± í–¥ìƒ)
        (label_width, label_height), baseline = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )
        cv2.rectangle(
            img_with_boxes,
            (x1, y1 - label_height - 10),
            (x1 + label_width, y1),
            color,
            -1  # ì±„ì›Œì§„ ì‚¬ê°í˜•
        )
        
        # ë ˆì´ë¸” í…ìŠ¤íŠ¸ (í°ìƒ‰)
        cv2.putText(
            img_with_boxes,
            label,
            (x1, y1 - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),  # í°ìƒ‰
            2
        )
        
        # JSON ì–´ë…¸í…Œì´ì…˜ ë°ì´í„° ìˆ˜ì§‘
        face_annotation = {
            "bbox": [x1, y1, x2, y2],
            "status": status,
            "name": name,
            "person_id": detection.get("person_id"),
            "confidence": confidence,
            "color": detection.get("color", "yellow"),
            "angle_type": detection.get("angle_type"),
            "yaw_angle": detection.get("yaw_angle"),
            "bank_type": detection.get("bank_type")
        }
        annotation["faces"].append(face_annotation)
    
    return {
        "image": img_with_boxes,
        "annotation": annotation,
        "detection_count": len(detections)
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ–¼ï¸  ì´ë¯¸ì§€ ë°°ì¹˜ ì¸ì‹ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 70)
    
    # 1. ì…ë ¥ í´ë” í™•ì¸
    if not TEST_IMAGE_DIR.exists():
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_IMAGE_DIR}")
        print(f"   í´ë”ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. ì¶œë ¥ í´ë” ìƒì„±
    OUTPUT_IMAGES_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_JSON_DIR.mkdir(parents=True, exist_ok=True)
    
    # 3. ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    image_files = [
        f for f in sorted(TEST_IMAGE_DIR.iterdir())
        if f.is_file() and f.suffix.lower() in IMG_EXTS
    ]
    
    if not image_files:
        print(f"âš ï¸ {TEST_IMAGE_DIR} ì•ˆì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“‚ ì…ë ¥ í´ë”: {TEST_IMAGE_DIR}")
    print(f"ğŸ“‚ ì¶œë ¥ í´ë”: {OUTPUT_DIR}")
    print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€: {len(image_files)}ê°œ")
    print()
    
    # 4. InsightFace ì´ˆê¸°í™”
    print("ğŸ”§ InsightFace ì´ˆê¸°í™” ì¤‘...")
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"   ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")
    
    model = FaceAnalysis(name="buffalo_l")
    actual_device_id = safe_prepare_insightface(model, device_id, det_size=(640, 640))
    if actual_device_id != device_id:
        print(f"   (ì‹¤ì œ ì‚¬ìš©: {'GPU' if actual_device_id >= 0 else 'CPU'})")
    print()
    
    # 5. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ë°ì´í„° ë¡œë“œ (base bankë§Œ ì‚¬ìš©)
    print("ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
    print("   âš ï¸ Base Bankë§Œ ì‚¬ìš© ëª¨ë“œ (Masked Bank ì œì™¸)")
    db = SessionLocal()
    try:
        load_persons_from_db(db)
        # Masked Bank ë¹„ìš°ê¸° (Base Bankë§Œ ì‚¬ìš©)
        from backend.main import gallery_masked_cache
        gallery_masked_cache.clear()
        print("   âœ… ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ (Base Bankë§Œ ì‚¬ìš©)")
    except Exception as e:
        print(f"   âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("   íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë¡œë“œ ì‹œë„...")
        from backend.main import load_persons_from_embeddings, gallery_masked_cache
        load_persons_from_embeddings()
        # Masked Bank ë¹„ìš°ê¸° (Base Bankë§Œ ì‚¬ìš©)
        gallery_masked_cache.clear()
        print("   âœ… íŒŒì¼ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ (Base Bankë§Œ ì‚¬ìš©)")
    
    # 6. ê° ì´ë¯¸ì§€ ì²˜ë¦¬
    print("\n" + "=" * 70)
    print("ğŸ”„ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 70)
    
    total_faces = 0
    processed_count = 0
    
    for image_path in image_files:
        try:
            result = process_single_image(image_path, db)
            
            if result is None:
                continue
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            output_image_path = OUTPUT_IMAGES_DIR / image_path.name
            cv2.imwrite(str(output_image_path), result["image"], [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            # JSON ì–´ë…¸í…Œì´ì…˜ ì €ì¥
            json_filename = image_path.stem + ".json"
            json_path = OUTPUT_JSON_DIR / json_filename
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result["annotation"], f, indent=2, ensure_ascii=False)
            
            face_count = result["detection_count"]
            total_faces += face_count
            processed_count += 1
            
            print(f"  âœ… ì™„ë£Œ: {image_path.name} (ê°ì§€ëœ ì–¼êµ´: {face_count}ê°œ)")
            
        except Exception as e:
            print(f"  âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {image_path.name} - {e}")
            import traceback
            traceback.print_exc()
    
    db.close()
    
    # 7. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
    print("=" * 70)
    print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
    print(f"   - ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_count}/{len(image_files)}ê°œ")
    print(f"   - ì´ ê°ì§€ëœ ì–¼êµ´: {total_faces}ê°œ")
    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
    print(f"   - ì´ë¯¸ì§€: {OUTPUT_IMAGES_DIR.relative_to(PROJECT_ROOT)}")
    print(f"   - JSON: {OUTPUT_JSON_DIR.relative_to(PROJECT_ROOT)}")
    print("=" * 70)


if __name__ == "__main__":
    main()

