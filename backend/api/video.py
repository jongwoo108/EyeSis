# backend/api/video.py
"""
ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ë¡œê·¸ API ì—”ë“œí¬ì¸íŠ¸
"""
import os
import json
import time
import tempfile
import subprocess
import cv2

from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import FileResponse
from sqlalchemy.orm import Session

from backend.database import get_db
from backend.services.face_detection import process_detection

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent

router = APIRouter()

@router.get("/api/logs")
async def get_logs(limit: int = 100, db: Session = Depends(get_db)):
    """ê°ì§€ ë¡œê·¸ ì¡°íšŒ"""
    from backend.database import DetectionLog
    try:
        logs = db.query(DetectionLog).order_by(DetectionLog.detected_at.desc()).limit(limit).all()
        return {
            "success": True,
            "count": len(logs),
            "logs": [
                {
                    "id": log.id,
                    "person_id": log.person_id,
                    "person_name": log.person_name,
                    "similarity": log.similarity,
                    "is_criminal": log.is_criminal,
                    "status": log.status,
                    "detected_at": log.detected_at.isoformat(),
                    "metadata": log.detection_metadata
                }
                for log in logs
            ]
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "count": 0,
            "logs": []
        }

@router.post("/api/extract_frames")
async def extract_frames(
    video: UploadFile = File(...)
):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ëª¨ë“  í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥ (ë¼ë²¨ë§ìš©)
    
    Args:
        video: ë¹„ë””ì˜¤ íŒŒì¼
    
    Returns:
        {
            "success": bool,
            "message": str,
            "total_frames": int,
            "output_dir": str
        }
    """
    try:
        print(f"ğŸ“¹ [EXTRACT FRAMES] í”„ë ˆì„ ì¶”ì¶œ ìš”ì²­: {video.filename}")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ë¹„ë””ì˜¤ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as input_file:
            input_path = input_file.name
            content = await video.read()
            input_file.write(content)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ë¹„ë””ì˜¤ íŒŒì¼ëª… ê¸°ë°˜)
        video_name = Path(video.filename).stem if video.filename else f"video_{int(time.time())}"
        output_dir = PROJECT_ROOT / "outputs" / "extracted_frames" / video_name
        annotations_dir = output_dir / "annotations"  # JSON íŒŒì¼ ì €ì¥ í´ë”
        output_dir.mkdir(parents=True, exist_ok=True)
        annotations_dir.mkdir(parents=True, exist_ok=True)
        
        # OpenCVë¡œ ë¹„ë””ì˜¤ ì—´ê¸°
        cap = cv2.VideoCapture(input_path)
        
        if not cap.isOpened():
            raise HTTPException(status_code=400, detail="ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"  ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:")
        print(f"     - ì´ í”„ë ˆì„: {total_frames}")
        print(f"     - FPS: {fps:.2f}")
        print(f"     - í•´ìƒë„: {width}x{height}")
        print(f"     - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"  ğŸ” ì–¼êµ´ ê°ì§€ ë° ë§¤ì¹­ ê²°ê³¼ ë°•ìŠ¤ ê·¸ë¦¬ê¸° í™œì„±í™”")
        
        # DB ì„¸ì…˜ ìƒì„± (ë§¤ì¹­ì„ ìœ„í•´ í•„ìš”)
        from backend.database import SessionLocal
        db = SessionLocal()
        
        try:
            # ëª¨ë“  í”„ë ˆì„ ì¶”ì¶œ (ë§¤ì¹­ ê²°ê³¼ í¬í•¨ ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
            frame_idx = 0
            saved_count = 0
            total_faces_detected = 0
            total_matches = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ë§¤ì¹­ ë¡œì§ ì‹¤í–‰ (ë¸Œë¼ìš°ì €ì—ì„œ ë³´ëŠ” ê²ƒê³¼ ë™ì¼í•œ ë¡œì§)
                # tracking_state ì´ˆê¸°í™” (tracks í‚¤ í•„ìš”)
                tracking_state = {"tracks": {}}
                
                detection_result = process_detection(
                    frame=frame,
                    suspect_ids=None,  # ì „ì²´ ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰
                    db=db,
                    tracking_state=tracking_state  # í”„ë ˆì„ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
                )
                
                # ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„ ë³µì‚¬
                frame_with_boxes = frame.copy()
                
                # ë§¤ì¹­ ê²°ê³¼ì— ë”°ë¼ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ë° JSON ë°ì´í„° ìˆ˜ì§‘
                detections = detection_result.get("detections", [])
                frame_annotations = {
                    "frame_idx": frame_idx,
                    "timestamp": frame_idx / fps if fps > 0 else 0.0,
                    "faces": []
                }
                
                for detection in detections:
                    bbox = detection["bbox"]
                    x1, y1, x2, y2 = bbox[0], bbox[1], bbox[2], bbox[3]
                    
                    # ìƒ‰ìƒ ê²°ì • (ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ ë¡œì§)
                    status = detection.get("status", "unknown")
                    if status == "criminal":
                        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                        label_color = (0, 0, 255)
                    elif status == "normal":
                        color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
                        label_color = (0, 255, 0)
                    else:  # unknown
                        color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (BGR)
                        label_color = (0, 255, 255)
                    
                    # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3)
                    cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 3)
                    
                    # ë ˆì´ë¸” ìƒì„± (ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ ì •ë³´)
                    name = detection.get("name", "Unknown")
                    confidence = detection.get("confidence", 0)
                    label = f"{name} ({confidence}%)"
                    
                    # ë ˆì´ë¸” ë°°ê²½ (ê°€ë…ì„± í–¥ìƒ)
                    (label_width, label_height), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    cv2.rectangle(
                        frame_with_boxes,
                        (x1, y1 - label_height - 10),
                        (x1 + label_width, y1),
                        color,
                        -1  # ì±„ì›Œì§„ ì‚¬ê°í˜•
                    )
                    
                    # ë ˆì´ë¸” í…ìŠ¤íŠ¸ (í°ìƒ‰)
                    cv2.putText(
                        frame_with_boxes,
                        label,
                        (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 255),  # í°ìƒ‰
                        2
                    )
                    
                    # JSON ì–´ë…¸í…Œì´ì…˜ ë°ì´í„° ìˆ˜ì§‘
                    face_annotation = {
                        "bbox": [int(x1), int(y1), int(x2), int(y2)],
                        "status": status,
                        "name": name,
                        "person_id": detection.get("person_id"),
                        "confidence": confidence,
                        "color": detection.get("color", "yellow"),
                        "angle_type": detection.get("angle_type"),
                        "yaw_angle": detection.get("yaw_angle"),
                        "bank_type": detection.get("bank_type")
                    }
                    frame_annotations["faces"].append(face_annotation)
                    
                    total_faces_detected += 1
                    if detection.get("status") != "unknown":
                        total_matches += 1
                
                # í”„ë ˆì„ ì €ì¥ (JPEG í˜•ì‹, ë§¤ì¹­ ê²°ê³¼ ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€)
                frame_filename = f"frame_{frame_idx:06d}.jpg"
                frame_path = output_dir / frame_filename
                cv2.imwrite(str(frame_path), frame_with_boxes, [cv2.IMWRITE_JPEG_QUALITY, 95])
                
                # JSON ì–´ë…¸í…Œì´ì…˜ ì €ì¥ (ì´ë¯¸ì§€ íŒŒì¼ê³¼ ìŒìœ¼ë¡œ ì €ì¥)
                json_filename = f"frame_{frame_idx:06d}.json"
                json_path = annotations_dir / json_filename
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(frame_annotations, f, indent=2, ensure_ascii=False)
                
                saved_count += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥ (100í”„ë ˆì„ë§ˆë‹¤)
                if frame_idx % 100 == 0:
                    progress = (frame_idx / total_frames * 100) if total_frames > 0 else 0
                    print(f"  â³ ì§„í–‰ ì¤‘: {frame_idx}/{total_frames} í”„ë ˆì„ ({progress:.1f}%), ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ, ë§¤ì¹­: {total_matches}ê°œ")
                
                frame_idx += 1
        finally:
            db.close()
        
        cap.release()
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(input_path)
        except:
            pass
        
        print(f"  âœ… í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {saved_count}ê°œ í”„ë ˆì„ ì €ì¥ë¨")
        print(f"  ğŸ‘¤ ì´ ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ")
        print(f"  âœ… ë§¤ì¹­ ì„±ê³µ: {total_matches}ê°œ")
        print(f"  ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        print(f"  ğŸ“„ JSON ì €ì¥ ìœ„ì¹˜: {annotations_dir}")
        
        return {
            "success": True,
            "message": f"{saved_count}ê°œì˜ í”„ë ˆì„ì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. (ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ, ë§¤ì¹­: {total_matches}ê°œ)",
            "total_frames": saved_count,
            "total_faces": total_faces_detected,
            "total_matches": total_matches,
            "output_dir": str(output_dir.relative_to(PROJECT_ROOT)),
            "annotations_dir": str(annotations_dir.relative_to(PROJECT_ROOT)),
            "video_info": {
                "fps": fps,
                "width": width,
                "height": height,
                "duration": total_frames / fps if fps > 0 else 0
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [EXTRACT FRAMES] í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"í”„ë ˆì„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@router.post("/api/extract_clip")
async def extract_clip(
    background_tasks: BackgroundTasks,
    video: UploadFile = File(...),
    start_time: float = Form(...),
    end_time: float = Form(...),
    person_name: str = Form("Unknown")
):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ íŠ¹ì • êµ¬ê°„ì„ ì¶”ì¶œí•˜ì—¬ í´ë¦½ ìƒì„±
    
    Args:
        video: ë¹„ë””ì˜¤ íŒŒì¼
        start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ)
        end_time: ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
        person_name: ë²”ì£„ì ì´ë¦„
    
    Returns:
        ì¶”ì¶œëœ í´ë¦½ íŒŒì¼
    """
    try:
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as input_file:
            input_path = input_file.name
            # ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ íŒŒì¼ ì €ì¥
            content = await video.read()
            input_file.write(content)
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
        
        # ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦½ ì¶”ì¶œ
        duration = end_time - start_time
        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-ss', str(start_time),
            '-t', str(duration),
            '-c', 'copy',  # ì¬ì¸ì½”ë”© ì—†ì´ ë³µì‚¬ (ë¹ ë¦„)
            '-avoid_negative_ts', 'make_zero',
            '-y',  # ë®ì–´ì“°ê¸°
            output_path
        ]
        
        print(f"ğŸ¬ í´ë¦½ ì¶”ì¶œ ì‹œì‘: {person_name} ({start_time:.1f}s - {end_time:.1f}s)")
        print(f"ğŸ“ ëª…ë ¹ì–´: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        
        if result.returncode != 0:
            print(f"âŒ ffmpeg ì˜¤ë¥˜: {result.stderr}")
            raise HTTPException(status_code=500, detail=f"í´ë¦½ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")
        
        # ì„ì‹œ ì…ë ¥ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(input_path)
        except:
            pass
        
        print(f"âœ… í´ë¦½ ì¶”ì¶œ ì™„ë£Œ: {output_path}")
        
        # ì‘ë‹µ í›„ íŒŒì¼ ì‚­ì œë¥¼ BackgroundTasksë¡œ ë“±ë¡
        background_tasks.add_task(os.unlink, output_path)
        
        # íŒŒì¼ ì‘ë‹µ ë°˜í™˜
        return FileResponse(
            output_path,
            media_type='video/mp4',
            filename=f"clip_{person_name}_{start_time:.1f}s-{end_time:.1f}s.mp4"
        )
        
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=500, detail="í´ë¦½ ì¶”ì¶œ ì‹œê°„ ì´ˆê³¼")
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="ffmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ffmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ í´ë¦½ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë¦½ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            if 'input_path' in locals():
                os.unlink(input_path)
        except:
            pass