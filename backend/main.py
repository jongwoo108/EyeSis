"""
FaceWatch FastAPI ë°±ì—”ë“œ ì„œë²„
ì›¹ í”„ë¡ íŠ¸ì—”ë“œì™€ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì„œë¹„ìŠ¤ ì œê³µ
PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
"""
import base64
import cv2
import numpy as np

import shutil
from typing import Optional, List, Dict, Set
from fastapi import FastAPI, HTTPException, Depends, WebSocket, WebSocketDisconnect, UploadFile, File, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pathlib import Path
from sqlalchemy.orm import Session

import json
import asyncio
import subprocess
import tempfile
import os
import time

import sys

from backend.utils.bbox_utils import (
    calculate_bbox_iou,
    calculate_bbox_center_distance,
    is_same_face_region
)
from backend.utils.image_utils import (
    l2_normalize,
    compute_cosine_similarity,
    preprocess_image_for_detection,
    base64_to_image,
    image_to_base64
)
from backend.utils.websocket_manager import(
    active_connections,
    connection_states,
    register_connection,
    unregister_connection
)
from backend.services import data_loader
from backend.services.data_loader import (
    load_persons_from_db,
    load_persons_from_embeddings,
    load_persons_from_legacy_files,
    find_person_info
)
from backend.services.bank_manager import(
    save_angle_separated_banks,
    add_embedding_to_bank_async,
    add_embedding_to_dynamic_bank_async,
    update_gallery_cache_in_memory
)
from backend.services.temporal_filter import apply_temporal_filter
from backend.services.face_detection import process_detection
from backend.models.schemas import DetectionRequest
from backend.api import persons


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CUDA ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì • (ê°€ì¥ ë¨¼ì € import)
from src.utils.device_config import _ensure_cuda_in_path
_ensure_cuda_in_path()

from insightface.app import FaceAnalysis
from src.utils.device_config import get_device_id, safe_prepare_insightface
from src.utils.gallery_loader import load_gallery, match_with_bank, match_with_bank_detailed
from src.utils.face_angle_detector import estimate_face_angle, is_diverse_angle, is_all_angles_collected, check_face_occlusion
from src.utils.mask_detector import estimate_mask_from_similarity, get_adjusted_threshold, estimate_face_quality
from src.face_enroll import get_main_face_embedding, save_embeddings, l2_normalize

# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë“ˆ
from backend.database import (
    get_db, get_all_persons, get_person_by_id,
    log_detection, init_db as db_init, Person
)

# ==========================================
# 1. ì„¤ì • ë° ê²½ë¡œ
# ==========================================


# Masked Bank ê´€ë ¨ ì„¤ì •
MASKED_BANK_MASK_PROB_THRESHOLD = 0.5  # mask_prob >= 0.5ì´ë©´ masked bankë¡œ ë¶„ë¥˜ (ì™„í™”: 0.7 â†’ 0.5)
MASKED_CANDIDATE_MIN_SIM = 0.25  # base_sim >= 0.25 ì´ìƒì´ì–´ì•¼ masked candidateë¡œ íŒë‹¨ (ì™„í™”: 0.30 â†’ 0.25)
MASKED_CANDIDATE_MIN_FRAMES = 3  # ì—°ì† N í”„ë ˆì„ ì´ìƒ ì¡°ê±´ ì¶©ì¡± ì‹œ masked bankì— ì¶”ê°€ (ì™„í™”: 5 â†’ 3)
MASKED_TRACKING_IOU_THRESHOLD = 0.5  # bbox trackingì„ ìœ„í•œ IoU ì„ê³„ê°’

# ==========================================
# 2. FastAPI ì•± ì´ˆê¸°í™”
# ==========================================

app = FastAPI(title="FaceWatch API", version="1.0.0")

# CORS í—ˆìš© (í”„ë¡ íŠ¸ì—”ë“œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ë¼ìš°í„° ë“±ë¡
from backend.api import detection
app.include_router(detection.router, tags=["detection"])
from backend.api import persons
app.include_router(persons.router, tags=["persons"])

# ==========================================
# 3. InsightFace ëª¨ë¸ ì´ˆê¸°í™” (device_config ì‚¬ìš©)
# ==========================================

print("=" * 70)
print("ğŸ”§ InsightFace ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
print("=" * 70)

device_id = get_device_id()
device_type = "GPU" if device_id >= 0 else "CPU"
print(f"ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")

model = FaceAnalysis(name="buffalo_l")
actual_device_id = safe_prepare_insightface(model, device_id, det_size=(640, 640))
if actual_device_id != device_id:
    print(f"   (ì‹¤ì œ ì‚¬ìš©: {'GPU' if actual_device_id >= 0 else 'CPU'})")
print()

# Inject model into face_detection module
from backend.services import face_detection
face_detection.set_model(model)



@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë“œ"""
    print("=" * 70)
    print("ğŸš€ FaceWatch ì„œë²„ ì‹œì‘")
    print("=" * 70)
    print("ğŸ“¡ WebSocket ì—”ë“œí¬ì¸íŠ¸:")
    print("   - /ws/detect (ë©”ì¸ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸)")
    print("   - /ws/test (í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸)")
    print("=" * 70)
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
    try:
        db_init()
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        print("   outputs/embeddingsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # 2. PostgreSQLì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
    try:
        db = next(get_db())
        try:
            load_persons_from_db(db)
        finally:
            db.close()
    except Exception as e:
        print(f"âš ï¸ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        print("   outputs/embeddingsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # Fallback: outputs/embeddings ì‚¬ìš©
        load_persons_from_embeddings()
    
    # 3. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²½ê³ 
    if not data_loader.gallery_base_cache and not data_loader.persons_cache:
        print("âš ï¸ ê²½ê³ : ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        print("   face_enroll.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë¬¼ì„ ë“±ë¡í•˜ê±°ë‚˜,")
        print("   python backend/init_db.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë§ˆì´ê·¸ë ˆì´ì…˜í•´ì£¼ì„¸ìš”.\n")




# ==========================================
# 7. ê³µí†µ ê°ì§€ ë¡œì§ í•¨ìˆ˜
# ==========================================


# ==========================================
# 8. API ì—”ë“œí¬ì¸íŠ¸
# ==========================================







@app.get("/api/logs")
async def get_logs(limit: int = 100, db: Session = Depends(get_db)):
    """ê°ì§€ ë¡œê·¸ ì¡°íšŒ"""
    from backend.database import DetectionLog
    try:
        logs = db.query(DetectionLog).order_by(DetectionLog.detected_at.desc()).limit(limit).all()
        return {
            "success": True,
            "count": len(logs),
            "logs": [
                {
                    "id": log.id,
                    "person_id": log.person_id,
                    "person_name": log.person_name,
                    "similarity": log.similarity,
                    "is_criminal": log.is_criminal,
                    "status": log.status,
                    "detected_at": log.detected_at.isoformat(),
                    "metadata": log.detection_metadata
                }
                for log in logs
            ]
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "count": 0,
            "logs": []
        }


@app.get("/api/images/enroll/{person_id}/{filename}")
async def get_person_image(person_id: str, filename: str):
    """ë“±ë¡ëœ ì¸ë¬¼ì˜ ì´ë¯¸ì§€ ì œê³µ"""
    image_path = PROJECT_ROOT / "images" / "enroll" / person_id / filename
    
    if not image_path.exists():
        raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë³´ì•ˆ ì²´í¬: person_idì™€ filenameì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    if image_path.parent.name != person_id:
        raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(image_path)

@app.post("/api/extract_frames")
async def extract_frames(
    video: UploadFile = File(...)
):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ëª¨ë“  í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥ (ë¼ë²¨ë§ìš©)
    
    Args:
        video: ë¹„ë””ì˜¤ íŒŒì¼
    
    Returns:
        {
            "success": bool,
            "message": str,
            "total_frames": int,
            "output_dir": str
        }
    """
    try:
        print(f"ğŸ“¹ [EXTRACT FRAMES] í”„ë ˆì„ ì¶”ì¶œ ìš”ì²­: {video.filename}")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ë¹„ë””ì˜¤ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as input_file:
            input_path = input_file.name
            content = await video.read()
            input_file.write(content)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ë¹„ë””ì˜¤ íŒŒì¼ëª… ê¸°ë°˜)
        video_name = Path(video.filename).stem if video.filename else f"video_{int(time.time())}"
        output_dir = PROJECT_ROOT / "outputs" / "extracted_frames" / video_name
        annotations_dir = output_dir / "annotations"  # JSON íŒŒì¼ ì €ì¥ í´ë”
        output_dir.mkdir(parents=True, exist_ok=True)
        annotations_dir.mkdir(parents=True, exist_ok=True)
        
        # OpenCVë¡œ ë¹„ë””ì˜¤ ì—´ê¸°
        cap = cv2.VideoCapture(input_path)
        
        if not cap.isOpened():
            raise HTTPException(status_code=400, detail="ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"  ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:")
        print(f"     - ì´ í”„ë ˆì„: {total_frames}")
        print(f"     - FPS: {fps:.2f}")
        print(f"     - í•´ìƒë„: {width}x{height}")
        print(f"     - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"  ğŸ” ì–¼êµ´ ê°ì§€ ë° ë§¤ì¹­ ê²°ê³¼ ë°•ìŠ¤ ê·¸ë¦¬ê¸° í™œì„±í™”")
        
        # DB ì„¸ì…˜ ìƒì„± (ë§¤ì¹­ì„ ìœ„í•´ í•„ìš”)
        from backend.database import SessionLocal
        db = SessionLocal()
        
        try:
            # ëª¨ë“  í”„ë ˆì„ ì¶”ì¶œ (ë§¤ì¹­ ê²°ê³¼ í¬í•¨ ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
            frame_idx = 0
            saved_count = 0
            total_faces_detected = 0
            total_matches = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ë§¤ì¹­ ë¡œì§ ì‹¤í–‰ (ë¸Œë¼ìš°ì €ì—ì„œ ë³´ëŠ” ê²ƒê³¼ ë™ì¼í•œ ë¡œì§)
                # tracking_state ì´ˆê¸°í™” (tracks í‚¤ í•„ìš”)
                tracking_state = {"tracks": {}}
                
                detection_result = process_detection(
                    frame=frame,
                    suspect_ids=None,  # ì „ì²´ ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰
                    db=db,
                    tracking_state=tracking_state  # í”„ë ˆì„ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
                )
                
                # ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„ ë³µì‚¬
                frame_with_boxes = frame.copy()
                
                # ë§¤ì¹­ ê²°ê³¼ì— ë”°ë¼ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ë° JSON ë°ì´í„° ìˆ˜ì§‘
                detections = detection_result.get("detections", [])
                frame_annotations = {
                    "frame_idx": frame_idx,
                    "timestamp": frame_idx / fps if fps > 0 else 0.0,
                    "faces": []
                }
                
                for detection in detections:
                    bbox = detection["bbox"]
                    x1, y1, x2, y2 = bbox[0], bbox[1], bbox[2], bbox[3]
                    
                    # ìƒ‰ìƒ ê²°ì • (ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ ë¡œì§)
                    status = detection.get("status", "unknown")
                    if status == "criminal":
                        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                        label_color = (0, 0, 255)
                    elif status == "normal":
                        color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
                        label_color = (0, 255, 0)
                    else:  # unknown
                        color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (BGR)
                        label_color = (0, 255, 255)
                    
                    # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3)
                    cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 3)
                    
                    # ë ˆì´ë¸” ìƒì„± (ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ ì •ë³´)
                    name = detection.get("name", "Unknown")
                    confidence = detection.get("confidence", 0)
                    label = f"{name} ({confidence}%)"
                    
                    # ë ˆì´ë¸” ë°°ê²½ (ê°€ë…ì„± í–¥ìƒ)
                    (label_width, label_height), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    cv2.rectangle(
                        frame_with_boxes,
                        (x1, y1 - label_height - 10),
                        (x1 + label_width, y1),
                        color,
                        -1  # ì±„ì›Œì§„ ì‚¬ê°í˜•
                    )
                    
                    # ë ˆì´ë¸” í…ìŠ¤íŠ¸ (í°ìƒ‰)
                    cv2.putText(
                        frame_with_boxes,
                        label,
                        (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 255),  # í°ìƒ‰
                        2
                    )
                    
                    # JSON ì–´ë…¸í…Œì´ì…˜ ë°ì´í„° ìˆ˜ì§‘
                    face_annotation = {
                        "bbox": [int(x1), int(y1), int(x2), int(y2)],
                        "status": status,
                        "name": name,
                        "person_id": detection.get("person_id"),
                        "confidence": confidence,
                        "color": detection.get("color", "yellow"),
                        "angle_type": detection.get("angle_type"),
                        "yaw_angle": detection.get("yaw_angle"),
                        "bank_type": detection.get("bank_type")
                    }
                    frame_annotations["faces"].append(face_annotation)
                    
                    total_faces_detected += 1
                    if detection.get("status") != "unknown":
                        total_matches += 1
                
                # í”„ë ˆì„ ì €ì¥ (JPEG í˜•ì‹, ë§¤ì¹­ ê²°ê³¼ ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€)
                frame_filename = f"frame_{frame_idx:06d}.jpg"
                frame_path = output_dir / frame_filename
                cv2.imwrite(str(frame_path), frame_with_boxes, [cv2.IMWRITE_JPEG_QUALITY, 95])
                
                # JSON ì–´ë…¸í…Œì´ì…˜ ì €ì¥ (ì´ë¯¸ì§€ íŒŒì¼ê³¼ ìŒìœ¼ë¡œ ì €ì¥)
                json_filename = f"frame_{frame_idx:06d}.json"
                json_path = annotations_dir / json_filename
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(frame_annotations, f, indent=2, ensure_ascii=False)
                
                saved_count += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥ (100í”„ë ˆì„ë§ˆë‹¤)
                if frame_idx % 100 == 0:
                    progress = (frame_idx / total_frames * 100) if total_frames > 0 else 0
                    print(f"  â³ ì§„í–‰ ì¤‘: {frame_idx}/{total_frames} í”„ë ˆì„ ({progress:.1f}%), ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ, ë§¤ì¹­: {total_matches}ê°œ")
                
                frame_idx += 1
        finally:
            db.close()
        
        cap.release()
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(input_path)
        except:
            pass
        
        print(f"  âœ… í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {saved_count}ê°œ í”„ë ˆì„ ì €ì¥ë¨")
        print(f"  ğŸ‘¤ ì´ ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ")
        print(f"  âœ… ë§¤ì¹­ ì„±ê³µ: {total_matches}ê°œ")
        print(f"  ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        print(f"  ğŸ“„ JSON ì €ì¥ ìœ„ì¹˜: {annotations_dir}")
        
        return {
            "success": True,
            "message": f"{saved_count}ê°œì˜ í”„ë ˆì„ì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. (ê°ì§€ëœ ì–¼êµ´: {total_faces_detected}ê°œ, ë§¤ì¹­: {total_matches}ê°œ)",
            "total_frames": saved_count,
            "total_faces": total_faces_detected,
            "total_matches": total_matches,
            "output_dir": str(output_dir.relative_to(PROJECT_ROOT)),
            "annotations_dir": str(annotations_dir.relative_to(PROJECT_ROOT)),
            "video_info": {
                "fps": fps,
                "width": width,
                "height": height,
                "duration": total_frames / fps if fps > 0 else 0
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [EXTRACT FRAMES] í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"í”„ë ˆì„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/api/extract_clip")
async def extract_clip(
    background_tasks: BackgroundTasks,
    video: UploadFile = File(...),
    start_time: float = Form(...),
    end_time: float = Form(...),
    person_name: str = Form("Unknown")
):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ íŠ¹ì • êµ¬ê°„ì„ ì¶”ì¶œí•˜ì—¬ í´ë¦½ ìƒì„±
    
    Args:
        video: ë¹„ë””ì˜¤ íŒŒì¼
        start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ)
        end_time: ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
        person_name: ë²”ì£„ì ì´ë¦„
    
    Returns:
        ì¶”ì¶œëœ í´ë¦½ íŒŒì¼
    """
    try:
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as input_file:
            input_path = input_file.name
            # ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ íŒŒì¼ ì €ì¥
            content = await video.read()
            input_file.write(content)
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
        
        # ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦½ ì¶”ì¶œ
        duration = end_time - start_time
        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-ss', str(start_time),
            '-t', str(duration),
            '-c', 'copy',  # ì¬ì¸ì½”ë”© ì—†ì´ ë³µì‚¬ (ë¹ ë¦„)
            '-avoid_negative_ts', 'make_zero',
            '-y',  # ë®ì–´ì“°ê¸°
            output_path
        ]
        
        print(f"ğŸ¬ í´ë¦½ ì¶”ì¶œ ì‹œì‘: {person_name} ({start_time:.1f}s - {end_time:.1f}s)")
        print(f"ğŸ“ ëª…ë ¹ì–´: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        
        if result.returncode != 0:
            print(f"âŒ ffmpeg ì˜¤ë¥˜: {result.stderr}")
            raise HTTPException(status_code=500, detail=f"í´ë¦½ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")
        
        # ì„ì‹œ ì…ë ¥ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(input_path)
        except:
            pass
        
        print(f"âœ… í´ë¦½ ì¶”ì¶œ ì™„ë£Œ: {output_path}")
        
        # ì‘ë‹µ í›„ íŒŒì¼ ì‚­ì œë¥¼ BackgroundTasksë¡œ ë“±ë¡
        background_tasks.add_task(os.unlink, output_path)
        
        # íŒŒì¼ ì‘ë‹µ ë°˜í™˜
        return FileResponse(
            output_path,
            media_type='video/mp4',
            filename=f"clip_{person_name}_{start_time:.1f}s-{end_time:.1f}s.mp4"
        )
        
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=500, detail="í´ë¦½ ì¶”ì¶œ ì‹œê°„ ì´ˆê³¼")
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="ffmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ffmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ í´ë¦½ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë¦½ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            if 'input_path' in locals():
                os.unlink(input_path)
        except:
            pass

# ==========================================
# Static Files ë§ˆìš´íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹™)
# ==========================================
# web í´ë”ì˜ ì •ì  íŒŒì¼ë“¤ì„ ë£¨íŠ¸ ê²½ë¡œë¡œ ì„œë¹™
# ì´ë ‡ê²Œ í•˜ë©´ ngrokìœ¼ë¡œ ì™¸ë¶€ ì ‘ì† ì‹œì—ë„ í•˜ë‚˜ì˜ URLë¡œ í†µí•© ê°€ëŠ¥
web_dir = PROJECT_ROOT / "web"
app.mount("/", StaticFiles(directory=str(web_dir), html=True), name="static")

# ì‹¤í–‰ ëª…ë ¹: uvicorn backend.main:app --reload --host 0.0.0.0 --port 5000
